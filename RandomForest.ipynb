{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c98a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d26a5655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset:\n",
      "  - reddit_data_counts.json (0.00 MB)\n",
      "  - reddit_dataset.json (11.27 MB)\n"
     ]
    }
   ],
   "source": [
    "# Set dataset path to RFdataset folder\n",
    "dataset_path = Path(\"RFdataset\")\n",
    "print(\"Files in dataset:\")\n",
    "for file in dataset_path.iterdir():\n",
    "    print(f\"  - {file.name} ({file.stat().st_size / (1024*1024):.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "234dff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: reddit_dataset.json\n",
      "File size: 11.27 MB\n",
      "\n",
      "Top-level keys: ['posts']\n",
      "\n",
      "Found 'posts' array with 6187 items\n",
      "\n",
      "Sample post structure:\n",
      "{\n",
      "  \"title\": \"Which country in the world suffers most from wage inequality and why?\",\n",
      "  \"body\": \"Shall we discuss this topic in the comments? I'm curious to hear your opinions. I have written my own thoughts below.\\r  \\n\\r  \\nMany sources and studies highlight countries like Brazil, South Africa, India, and the United States as standing out in terms of income inequality. Inequality factors in these countries can include high income inequality, challenging working conditions faced by low-wage workers, racial or ethnic discrimination, gender inequality, and social class disparities.\\r  \\n\\r  \\nThe causes of income inequality in these countries can be complex and multifaceted. For example, high income inequality can sometimes reflect a wide economic gap between the rich and the poor. Challenging working conditions experienced by low-wage workers can arise from factors such as low job security, low wages, and limited social safety nets. One of the major causes, of course, is poor governanc\n",
      "\n",
      "Keys in post: ['title', 'body', 'url', 'post_score', 'comment', 'comment_score']\n"
     ]
    }
   ],
   "source": [
    "# Explore JSON structure from reddit_dataset.json\n",
    "json_file = dataset_path / \"reddit_dataset.json\"\n",
    "\n",
    "if json_file.exists():\n",
    "    print(f\"Loading: {json_file.name}\")\n",
    "    print(f\"File size: {json_file.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Load and explore structure\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        print(\"\\nTop-level keys:\", list(data.keys()))\n",
    "        \n",
    "        # Check if it has a \"posts\" key\n",
    "        if 'posts' in data:\n",
    "            print(f\"\\nFound 'posts' array with {len(data['posts'])} items\")\n",
    "            if len(data['posts']) > 0:\n",
    "                sample_post = data['posts'][0]\n",
    "                print(\"\\nSample post structure:\")\n",
    "                print(json.dumps(sample_post, indent=2)[:1000])  # First 1000 chars\n",
    "                print(\"\\nKeys in post:\", list(sample_post.keys()))\n",
    "        else:\n",
    "            print(\"\\nFull data structure (first 1000 chars):\")\n",
    "            print(json.dumps(data, indent=2)[:1000])\n",
    "else:\n",
    "    print(f\"File not found: {json_file}\")\n",
    "    print(\"Available files:\")\n",
    "    for file in dataset_path.iterdir():\n",
    "        print(f\"  - {file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c689fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reddit_dataset.json...\n",
      "Loaded 6187 posts from 'posts' array\n",
      "\n",
      "Total records loaded: 6187\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data from reddit_dataset.json\n",
    "json_file = dataset_path / \"reddit_dataset.json\"\n",
    "\n",
    "print(f\"Loading {json_file.name}...\")\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    # Extract posts array\n",
    "    if 'posts' in data:\n",
    "        raw_data = data['posts']\n",
    "        print(f\"Loaded {len(raw_data)} posts from 'posts' array\")\n",
    "    elif isinstance(data, list):\n",
    "        raw_data = data\n",
    "        print(f\"Loaded {len(raw_data)} items from JSON array\")\n",
    "    else:\n",
    "        # If it's a single object, wrap it in a list\n",
    "        raw_data = [data]\n",
    "        print(f\"Loaded 1 item from JSON object\")\n",
    "\n",
    "print(f\"\\nTotal records loaded: {len(raw_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01eb0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (6187, 6)\n",
      "\n",
      "Columns: ['title', 'body', 'url', 'post_score', 'comment', 'comment_score']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "      <th>post_score</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which country in the world suffers most from w...</td>\n",
       "      <td>Shall we discuss this topic in the comments? I...</td>\n",
       "      <td>https://www.reddit.com/r/business/comments/14e...</td>\n",
       "      <td>3</td>\n",
       "      <td>Close your eyes, and you can choose one of the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Passion</td>\n",
       "      <td>Does your work drive you? Or is it something y...</td>\n",
       "      <td>https://www.reddit.com/r/business/comments/14e...</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow, you and I are the same person. Haha, exce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biz Savings Interest Rates</td>\n",
       "      <td>I‚Äôm assuming the answer is obviously that the ...</td>\n",
       "      <td>https://www.reddit.com/r/business/comments/14e...</td>\n",
       "      <td>2</td>\n",
       "      <td>I think your assumption is correct, businesses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How much is international ocean freight?</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/business/comments/14e...</td>\n",
       "      <td>1</td>\n",
       "      <td>Way too vague to be answered.\\nFrom where to w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello everyone I want to start a low budget bu...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.reddit.com/r/business/comments/14e...</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks üôè</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Which country in the world suffers most from w...   \n",
       "1                                            Passion   \n",
       "2                         Biz Savings Interest Rates   \n",
       "3           How much is international ocean freight?   \n",
       "4  Hello everyone I want to start a low budget bu...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Shall we discuss this topic in the comments? I...   \n",
       "1  Does your work drive you? Or is it something y...   \n",
       "2  I‚Äôm assuming the answer is obviously that the ...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                 url  post_score  \\\n",
       "0  https://www.reddit.com/r/business/comments/14e...           3   \n",
       "1  https://www.reddit.com/r/business/comments/14e...           1   \n",
       "2  https://www.reddit.com/r/business/comments/14e...           2   \n",
       "3  https://www.reddit.com/r/business/comments/14e...           1   \n",
       "4  https://www.reddit.com/r/business/comments/14e...           1   \n",
       "\n",
       "                                             comment  comment_score  \n",
       "0  Close your eyes, and you can choose one of the...              5  \n",
       "1  Wow, you and I are the same person. Haha, exce...              1  \n",
       "2  I think your assumption is correct, businesses...              1  \n",
       "3  Way too vague to be answered.\\nFrom where to w...              1  \n",
       "4                                           Thanks üôè              2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame and explore\n",
    "df = pd.DataFrame(raw_data)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20d41db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "title            object\n",
      "body             object\n",
      "url              object\n",
      "post_score        int64\n",
      "comment          object\n",
      "comment_score     int64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_score</th>\n",
       "      <th>comment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6187.000000</td>\n",
       "      <td>6187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>517.082916</td>\n",
       "      <td>191.261516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1970.486668</td>\n",
       "      <td>1102.608781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>315.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42256.000000</td>\n",
       "      <td>26998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         post_score  comment_score\n",
       "count   6187.000000    6187.000000\n",
       "mean     517.082916     191.261516\n",
       "std     1970.486668    1102.608781\n",
       "min        0.000000   -1547.000000\n",
       "25%        1.000000       4.000000\n",
       "50%       13.000000      16.000000\n",
       "75%      315.000000     106.000000\n",
       "max    42256.000000   26998.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types and basic stats\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97955c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "post_score:\n",
      "  Q1: 1.00, Q3: 315.00, IQR: 314.00\n",
      "  Outlier bounds: [-470.00, 786.00]\n",
      "  Number of outliers: 702 (11.35%)\n",
      "  Min: 0, Max: 42256\n",
      "\n",
      "comment_score:\n",
      "  Q1: 4.00, Q3: 106.00, IQR: 102.00\n",
      "  Outlier bounds: [-149.00, 259.00]\n",
      "  Number of outliers: 692 (11.18%)\n",
      "  Min: -1547, Max: 26998\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "numeric_cols = ['post_score', 'comment_score']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "        print(f\"  Outlier bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(f\"  Number of outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "        print(f\"  Min: {df[col].min()}, Max: {df[col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f94907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded subreddit frequencies from reddit_data_counts.json\n",
      "Original columns: 6\n",
      "Features after engineering: 25\n",
      "\n",
      "New features created:\n",
      "['subreddit', 'combined_text', 'text_length', 'word_count', 'has_text', 'title_length', 'title_word_count', 'body_length', 'body_word_count', 'has_question_mark', 'has_exclamation', 'uppercase_ratio', 'score', 'comment_to_score_ratio', 'total_engagement', 'has_comment', 'comment_length', 'subreddit_frequency', 'subreddit_encoded']\n"
     ]
    }
   ],
   "source": [
    "# Create features from raw data for Random Forest\n",
    "def extract_features(df):\n",
    "    features_df = df.copy()\n",
    "    \n",
    "    # 1. Extract subreddit from URL\n",
    "    if 'url' in features_df.columns:\n",
    "        features_df['subreddit'] = features_df['url'].astype(str).str.extract(r'/r/([^/]+)/')\n",
    "    \n",
    "    # 2. Text-based features (combine title and body)\n",
    "    if 'title' in features_df.columns and 'body' in features_df.columns:\n",
    "        features_df['combined_text'] = (\n",
    "            features_df['title'].astype(str) + ' ' + features_df['body'].astype(str)\n",
    "        )\n",
    "        text_col = 'combined_text'\n",
    "    elif 'title' in features_df.columns:\n",
    "        text_col = 'title'\n",
    "        features_df['combined_text'] = features_df['title'].astype(str)\n",
    "    elif 'body' in features_df.columns:\n",
    "        text_col = 'body'\n",
    "        features_df['combined_text'] = features_df['body'].astype(str)\n",
    "    else:\n",
    "        text_col = None\n",
    "    \n",
    "    if text_col:\n",
    "        # Character and word counts\n",
    "        features_df['text_length'] = features_df['combined_text'].str.len()\n",
    "        features_df['word_count'] = features_df['combined_text'].str.split().str.len()\n",
    "        features_df['has_text'] = (features_df['combined_text'].str.len() > 0).astype(int)\n",
    "        \n",
    "        # Title-specific features\n",
    "        if 'title' in features_df.columns:\n",
    "            features_df['title_length'] = features_df['title'].astype(str).str.len()\n",
    "            features_df['title_word_count'] = features_df['title'].astype(str).str.split().str.len()\n",
    "        \n",
    "        # Body-specific features\n",
    "        if 'body' in features_df.columns:\n",
    "            features_df['body_length'] = features_df['body'].astype(str).str.len()\n",
    "            features_df['body_word_count'] = features_df['body'].astype(str).str.split().str.len()\n",
    "        \n",
    "        # Text patterns (use regex=False to treat ? and ! as literal characters)\n",
    "        features_df['has_question_mark'] = features_df['combined_text'].str.contains('?', regex=False, na=False).astype(int)\n",
    "        features_df['has_exclamation'] = features_df['combined_text'].str.contains('!', regex=False, na=False).astype(int)\n",
    "        features_df['uppercase_ratio'] = features_df['combined_text'].apply(\n",
    "            lambda x: sum(1 for c in str(x) if c.isupper()) / len(str(x)) if len(str(x)) > 0 else 0\n",
    "        )\n",
    "    \n",
    "    # 3. Engagement metrics\n",
    "    if 'post_score' in features_df.columns:\n",
    "        features_df['score'] = pd.to_numeric(features_df['post_score'], errors='coerce').fillna(0)\n",
    "    elif 'score' in features_df.columns:\n",
    "        features_df['score'] = pd.to_numeric(features_df['score'], errors='coerce').fillna(0)\n",
    "    \n",
    "    if 'comment_score' in features_df.columns:\n",
    "        features_df['comment_score'] = pd.to_numeric(features_df['comment_score'], errors='coerce').fillna(0)\n",
    "        features_df['comment_to_score_ratio'] = features_df['comment_score'] / (features_df['score'] + 1)\n",
    "        features_df['total_engagement'] = features_df['score'] + features_df['comment_score']\n",
    "    \n",
    "    if 'comment' in features_df.columns:\n",
    "        features_df['has_comment'] = (features_df['comment'].astype(str).str.len() > 0).astype(int)\n",
    "        features_df['comment_length'] = features_df['comment'].astype(str).str.len()\n",
    "    \n",
    "    # 4. Subreddit features (encode categorical)\n",
    "    if 'subreddit' in features_df.columns:\n",
    "        # Load subreddit frequency from reddit_data_counts.json\n",
    "        counts_file = dataset_path / \"reddit_data_counts.json\"\n",
    "        if counts_file.exists():\n",
    "            with open(counts_file, 'r', encoding='utf-8') as f:\n",
    "                subreddit_freq_dict = json.load(f)\n",
    "            # Map subreddit frequencies from the JSON file\n",
    "            features_df['subreddit_frequency'] = features_df['subreddit'].map(subreddit_freq_dict).fillna(0)\n",
    "            print(f\"Loaded subreddit frequencies from {counts_file.name}\")\n",
    "        else:\n",
    "            # Fallback: calculate from dataset if JSON file not found\n",
    "            subreddit_counts = features_df['subreddit'].value_counts()\n",
    "            features_df['subreddit_frequency'] = features_df['subreddit'].map(subreddit_counts)\n",
    "            print(\"Warning: reddit_data_counts.json not found. Using calculated frequencies.\")\n",
    "        \n",
    "        # Numeric encoding for Random Forest (based on unique subreddits in dataset)\n",
    "        unique_subreddits = features_df['subreddit'].dropna().unique()\n",
    "        subreddit_encoding = {sub: idx for idx, sub in enumerate(unique_subreddits)}\n",
    "        features_df['subreddit_encoded'] = features_df['subreddit'].map(subreddit_encoding).fillna(-1)\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Apply feature engineering\n",
    "df_features = extract_features(df)\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"Features after engineering: {len(df_features.columns)}\")\n",
    "print(f\"\\nNew features created:\")\n",
    "new_cols = [col for col in df_features.columns if col not in df.columns]\n",
    "print(new_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f284207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "subreddit    1258\n",
      "dtype: int64\n",
      "\n",
      "Missing values after handling:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Handle  missing values\n",
    "missing_before = df_features.isnull().sum()\n",
    "print(\"Missing values before handling:\")\n",
    "print(missing_before[missing_before > 0])\n",
    "\n",
    "# Fill missing values\n",
    "df_features = df_features.fillna(0)\n",
    "\n",
    "missing_after = df_features.isnull().sum()\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(missing_after[missing_after > 0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs171",
   "language": "python",
   "name": "cs171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
